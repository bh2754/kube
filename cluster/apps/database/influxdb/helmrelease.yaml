---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: influxdb
  namespace: database
spec:
  interval: 5m
  chart:
    spec:
      # renovate: registryUrl=https://helm.influxdata.com/
      chart: influxdb
      version: 4.12.0
      sourceRef:
        kind: HelmRepository
        name: influxdata-charts
        namespace: flux-system
      interval: 5m
  install:
    timeout: 10m
    remediation:
      retries: 3
  upgrade:
    timeout: 10m
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true
  rollback:
    timeout: 10m
    recreate: true
    cleanupOnFail: true
  values:
    ## influxdb image version
    ## ref: https://hub.docker.com/r/library/influxdb/tags/
    image:
      repository: "influxdb"
      tag: "2.6.0-alpine"
      pullPolicy: IfNotPresent
      ## If specified, use these secrets to access the images
      # pullSecrets:
      #   - registry-secret


    serviceAccount:
      create: true
      name:
      annotations: {}

    ## Customize liveness, readiness and startup probes
    ## ref: https://docs.influxdata.com/influxdb/v1.8/tools/api/#ping-http-endpoint
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
    ##
    livenessProbe: {}
      # path: "/ping"
      # initialDelaySeconds: 30
      # timeoutSeconds: 5
      # scheme: HTTP

    readinessProbe: {}
      # path: "/ping"
      # initialDelaySeconds: 5
      # timeoutSeconds: 1
      # scheme: HTTP

    securityContext: {}
      # runAsUser: 999
      # runAsGroup: 999

    startupProbe:
      enabled: false
      # path: "/ping"
      # failureThreshold: 6
      # periodSeconds: 5
      # scheme: HTTP

    ## Specify a service type and optional port
    ## NodePort is default
    ## ref: http://kubernetes.io/docs/user-guide/services/
    ##
    service:
      type: LoadBalancer
      annotations:
        metallb.universe.tf/loadBalancerIPs: "${METALLB_INFLUXDB_IP}"

      ## Add annotations to service
      # annotations: {}
      # type: loadBalancer
      # externalTrafficPolicy: ""
      # nodePort(s) value for the LoadBalancer and NodePort service types
      nodePorts:
        http: ""

    ## Persist data to a persistent volume
    ##
    persistence:
      enabled: true
      ## A manually managed Persistent Volume and Claim
      ## Requires persistence.enabled: true
      ## If defined, PVC must be created manually before volume will be bound
      existingClaim: influxdb-data
      ## influxdb data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      storageClass: "longhorn"
      accessMode: ReadWriteOnce
    setDefaultUser:
      enabled: false
      user:
        existingSecret: influxdb-auth
    resources:
      requests:
        memory: 105M
        cpu: 15m
      limits:
        memory: 143M

    # Annotations to be added to InfluxDB pods
    podAnnotations: {}

    # Labels to be added to InfluxDB pods
    podLabels: {}

    ingress:
      enabled: true
      ingressClassName: "nginx"
      tls: true
      secretName: "influx-tls"
      hostname: influxdb.bharris.xyz
      className: null
      annotations:
        cert-manager.io/cluster-issuer: "letsencrypt-production"
        kubernetes.io/ingress.class: "nginx"
      path: /
    extraContainers: {}
    #  - name: my-sidecar
    #    image: nginx:latest

    ## Use an alternate scheduler, e.g. "stork".
    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/
    ##
    # schedulerName:

    ## Node labels for pod assignment
    ## Ref: https://kubernetes.io/docs/user-guide/node-selection/
    ##
    nodeSelector: {}

    ## Affinity for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
    ##
    affinity: {}

    ## Tolerations for pod assignment
    ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
    ##
    tolerations: []
    # - key: "key"
    #   operator: "Equal|Exists"
    #   value: "value"
    #   effect: "NoSchedule|PreferNoSchedule|NoExecute(1.6 only)"

    ## The InfluxDB image uses several environment variables to automatically
    ## configure certain parts of the server.
    ## Ref: https://hub.docker.com/_/influxdb/
    env: {}
      # - name: INFLUXDB_DB
      #   value: "demo"

    ## The name of a secret in the same kubernetes namespace which contain values
    ## to be added to the environment.
    ## This can be used, for example, to set the INFLUXDB_HTTP_SHARED_SECRET
    ## environment variable.
    envFromSecret: {}

    ## InfluxDB configuration
    ## ref: https://docs.influxdata.com/influxdb/v1.8/administration/config
    config:
      reporting_disabled: false
      rpc: {}
      meta: {}
      data: {}
      coordinator: {}
      retention: {}
      shard_precreation: {}
      monitor: {}
      http: {}
      logging: {}
      subscriber: {}
      graphite: {}
      collectd: {}
      opentsdb:
        enabled: true
        bind-address: :4242
        database: opentsdb
      # retention-policy: ""
      # consistency-level: one
        tls-enabled: false
        log-point-errors: true
        batch-size: 1000
        batch-pending: 5
        batch-timeout: 1s
      udp: {}
      continuous_queries: {}
      tls: {}

    # Allow executing custom init scripts
    #
    # If the container finds any files with the extensions .sh or .iql inside of the
    # /docker-entrypoint-initdb.d folder, it will execute them. The order they are
    # executed in is determined by the shell. This is usually alphabetical order.
    initScripts:
      enabled: false
      scripts:
        init.iql: |+
          CREATE DATABASE "telegraf" WITH DURATION 30d REPLICATION 1 NAME "rp_30d"
          CREATE DATABASE "opentsdb" WITH DURATION 30d REPLICATION 1 NAME "rp1_30d"
          CREATE DATABASE "varken" WITH DURATION 30d REPLICATION 1 NAME "rp_30d"
    backup:
      enabled: false
      ## By default emptyDir is used as a transitory volume before uploading to object store.
      ## As such, ensure that a sufficient ephemeral storage request is set to prevent node disk filling completely.
      resources:
        requests:
          # memory: 512Mi
          # cpu: 2
          ephemeral-storage: "8Gi"
        # limits:
          # memory: 1Gi
          # cpu: 4
          # ephemeral-storage: "16Gi"
      ## If backup destination is PVC, or want to use intermediate PVC before uploading to object store.
      persistence:
        enabled: false
        ## If defined, storageClassName: <storageClass>
        ## If set to "-", storageClassName: "", which disables dynamic provisioning
        ## If undefined (the default) or set to null, no storageClassName spec is
        ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
        ##   GKE, AWS & OpenStack)
        ##
        # storageClass: "-"
        annotations:
        accessMode: ReadWriteOnce
        size: 8Gi
      schedule: "0 0 * * *"
      startingDeadlineSeconds: ""
      annotations: {}
      podAnnotations: {}
      nodeSelector: {}

      ## Google Cloud Storage
      # gcs:
        # serviceAccountSecret: influxdb-backup-key
        # serviceAccountSecretKey: key.json
        # destination: gs://bucket/influxdb

      ## Azure
      ## Secret is expected to have connection string stored in `connection-string` field
      ## Existing container will be used or private one withing storage account will be created.
      # azure:
        # storageAccountSecret: influxdb-backup-azure-key
        # destination_container: influxdb-container
        # destination_path: ""

      ## Amazon S3 or compatible
      ## Secret is expected to have AWS (or compatible) credentials stored in `credentials` field.
      ## Please look at https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-files.html#cli-configure-files-where
      ## for the credentials format.
      ## The bucket should already exist.
      # s3:
        # credentialsSecret: aws-credentials-secret
        # destination: s3://bucket/path
        ## Optional. Specify if you're using an alternate S3 endpoint.
        # endpointUrl: ""

    backupRetention:
      enabled: false
      resources:
        requests:
          # memory: 512Mi
          # cpu: 2
        # limits:
          # memory: 1Gi
          # cpu: 4
      schedule: "0 0 * * *"
      startingDeadlineSeconds:
      annotations: {}
      podAnnotations: {}
      daysToRetain: 7
      # s3:
      #   credentialsSecret: aws-credentials-secret
      #   bucketName: bucket
      #   ## Optional. Specify if you're using an alternate S3 endpoint.
      #   # endpointUrl: ""
